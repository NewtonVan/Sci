# A Free Lunch for Unsupervised Domain Adaptive Object Detection without Source Data

***

* Motivation: 

  * Existing method assuming that the data distribution of labeled source domain and unlabeled target domain is **related but different** and **needing access freely** to both source and target domain samples. However, this assumption will encounter challenges in practical application, such as **data privacy** and **impractical data transmission**.
  * There is still a blank in the source data-free unsupervised domain adaptive object detection.
  * train the target model with **reliable pseudo labels** of target samples in a self-learning manner.
  * An appropriate **confidence threshold** for pseudo label generation is the key to make a trade-off between the positive effect brought by true positives and the negative effect brought by false positives and false negatives.

* Method

  * Conclusion from toy example

    * Noise degree is positively correlated with mean self-entropy. 
    * A reliable label assignment when mean self-entropy descends and hits the local minimum

  * Self-entropy descent(SED)

    * pseudo labels $y(x_t)$ and the corresponding confidence $p(x_t)$ can be obtained as follows: $\{y(x_t^i), p(x_t^i)\}=\{F(x_t^i|h, \theta_s)\}$
    * $\theta_s$ is the source domain's pre-trained model's parameter, $h$ is a confidence threshold for pseudo label generation, $F$ represents Faster-RCNN
    * After fine-tuning the pre-trained model with the pseudo-labels generated by a given $h$, we use the updated model $\theta_t$ to evaluate the mean self-entropy $H(D_t)$ of the target datasets.
    * Search the confidence threshold from the higher to lower score, and early stop when self-entropy descends and hit the first local minimum

  * False Negatives Simulation

    * > And surprisingly, more than 50% positive samples are difficult to box out even though we set the confidence threshold close to zero, which behave as false negatives during training.

    * **Note**: In my opinion, this is not a surprising result because of the structure of SED naturally lead to this. Setting a threshold is an exclusive method, which means it tends to exclude positives.

    * > The domain gap between the source domain and target domain increases the difficulty of detecting hard examples.

    * > Data augmentation is a good way to augment the detected positives into hard ones to simulate the small and obscured objects. It can suppress the negative effects of false negatives. 

    * Mosaic augmentation is selected

    * > The two main steps in Mosaic are random scaling and random cutting. 

* Experiments

  * model is pre-trained

  * Adaptation to A New Sense

    * > When SED is used alone, although the ideal confidence threshold searched by the labeled target validation set is not found, the AP is very close to the ideal one, and our method has surpassed many existing methods in terms of car detection accuracy.

    * > When Mosaic is further used, the AP can be increased from 43.6% to 44.6% and exceeds DA-Detection (Hsu et al. 2020) by 0.7%. We can see that false negatives simulation can ease the negative effect brought by the false negative noisy labels.

  * Adaptation to Large-Scale Dataset

    * > resolving such a domain divergence between a source domain and a target domain is so complicated that only a handful of approaches challenge this adaptation task, let alone source data-free.

    * > that the state-of-the-art methods are improved over a wide range of confidence thresholds.

    * > Especially when we use SED or SED+Mosaic, we can improve the mAP from 26.9% of CR-DA-DET (Xu et al. 2020) to 27.6% and 29.0%.

  * Adaptation from Normal to Foggy Weather

    * > there is still a certain gap to achieve the performance of the traditional UDA object detection methods

    * > SFOD performance has been improved by approximately 3% after defogging

    * > it can be concluded that the fog aggravates the label noise in pseudo labels, thus affecting the detection performance.

  * Discussion and Analysis

    * > SED combining with false negatives simulation, the negative effects brought by  noisy labels can be well suppressed  so that more objects can be detected

    * > Our proposed SFOD achieves comparable even superior results to the existing source data based UDA methods, which means the source domain data is actually not fully exploited in the existing methods.

* **Note**

  * This method give me a sense that SED is try to align source domain and target domain in an indirect way.
  * Actually, at first time, I didn't expect a good result about this work. However, from the experiment, it surprisingly get a pretty well result.

